{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the data and printing first 5 rows\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes #dataypes of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum() #checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts() #checking for the number of values of fraud and not fraud class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace= True) #dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of fraud transaction:  0.1667101358352777\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of fraud transaction: \", df.Class.value_counts()[1]/len(df.Class) *100) #%of fraud transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94811.077600</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>88.472687</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47481.047891</td>\n",
       "      <td>1.948026</td>\n",
       "      <td>1.646703</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>1.414184</td>\n",
       "      <td>1.377008</td>\n",
       "      <td>1.331931</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>1.179054</td>\n",
       "      <td>1.095492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723909</td>\n",
       "      <td>0.724550</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.521220</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.395744</td>\n",
       "      <td>0.328027</td>\n",
       "      <td>250.399437</td>\n",
       "      <td>0.040796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54204.750000</td>\n",
       "      <td>-0.915951</td>\n",
       "      <td>-0.600321</td>\n",
       "      <td>-0.889682</td>\n",
       "      <td>-0.850134</td>\n",
       "      <td>-0.689830</td>\n",
       "      <td>-0.769031</td>\n",
       "      <td>-0.552509</td>\n",
       "      <td>-0.208828</td>\n",
       "      <td>-0.644221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228305</td>\n",
       "      <td>-0.542700</td>\n",
       "      <td>-0.161703</td>\n",
       "      <td>-0.354453</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.070641</td>\n",
       "      <td>-0.052818</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.500000</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>-0.053468</td>\n",
       "      <td>-0.275168</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>-0.052172</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139298.000000</td>\n",
       "      <td>1.316068</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>1.026960</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.439738</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>0.240261</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>77.510000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean    94811.077600       0.005917      -0.004135       0.001613   \n",
       "std     47481.047891       1.948026       1.646703       1.508682   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54204.750000      -0.915951      -0.600321      -0.889682   \n",
       "50%     84692.500000       0.020384       0.063949       0.179963   \n",
       "75%    139298.000000       1.316068       0.800283       1.026960   \n",
       "max    172792.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean       -0.002966       0.001828      -0.001139       0.001801   \n",
       "std         1.414184       1.377008       1.331931       1.227664   \n",
       "min        -5.683171    -113.743307     -26.160506     -43.557242   \n",
       "25%        -0.850134      -0.689830      -0.769031      -0.552509   \n",
       "50%        -0.022248      -0.053468      -0.275168       0.040859   \n",
       "75%         0.739647       0.612218       0.396792       0.570474   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  283726.000000  283726.000000  ...  283726.000000  283726.000000   \n",
       "mean       -0.000854      -0.001596  ...      -0.000371      -0.000015   \n",
       "std         1.179054       1.095492  ...       0.723909       0.724550   \n",
       "min       -73.216718     -13.434066  ...     -34.830382     -10.933144   \n",
       "25%        -0.208828      -0.644221  ...      -0.228305      -0.542700   \n",
       "50%         0.021898      -0.052596  ...      -0.029441       0.006675   \n",
       "75%         0.325704       0.595977  ...       0.186194       0.528245   \n",
       "max        20.007208      15.594995  ...      27.202839      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean        0.000198       0.000214      -0.000232       0.000149   \n",
       "std         0.623702       0.605627       0.521220       0.482053   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161703      -0.354453      -0.317485      -0.326763   \n",
       "50%        -0.011159       0.041016       0.016278      -0.052172   \n",
       "75%         0.147748       0.439738       0.350667       0.240261   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000  \n",
       "mean        0.001763       0.000547      88.472687       0.001667  \n",
       "std         0.395744       0.328027     250.399437       0.040796  \n",
       "min       -22.565679     -15.430084       0.000000       0.000000  \n",
       "25%        -0.070641      -0.052818       5.600000       0.000000  \n",
       "50%         0.001479       0.011288      22.000000       0.000000  \n",
       "75%         0.091208       0.078276      77.510000       0.000000  \n",
       "max        31.612198      33.847808   25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #more info about the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Class.hist() #visually interpreting the transactions. Clear class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #scaling down the amount feature\n",
    "df['NormAmount'] = MinMaxScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>NormAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
       "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Amount  Class  NormAmount  \n",
       "0  0.133558 -0.021053  149.62      0    0.005824  \n",
       "1 -0.008983  0.014724    2.69      0    0.000105  \n",
       "2 -0.055353 -0.059752  378.66      0    0.014739  \n",
       "3  0.062723  0.061458  123.50      0    0.004807  \n",
       "4  0.219422  0.215153   69.99      0    0.002724  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy() #creating copy of dataframe\n",
    "df1.drop(columns=[\"Amount\"],axis=1,inplace=True) #dropping the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for training and testing\n",
    "from sklearn.model_selection import train_test_split \n",
    "X = df1.drop(['Class'],axis=1)\n",
    "y = df1[\"Class\"]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    198274\n",
      "1       334\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84979\n",
      "           1       0.56      0.78      0.65       139\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.78      0.89      0.82     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n",
      "0.9986254376277638\n"
     ]
    }
   ],
   "source": [
    "#applying logistics regression and printing out the classification report\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_lr))\n",
    "print(accuracy_score(y_test,y_pred_lr))\n",
    "\n",
    "#OBSERVATIONS: 1. precision and recall is 1 for majority class, it occured due to imbalanced dataset that we have.\n",
    "# 2. For fraud transaction, recall i.e. detecting whether the transaction is fraud is less\n",
    "# 3. Precision i.e. predicting whether the transaction is fraud is also less"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=20,k_neighbors = 5)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    198274\n",
       "0    198274\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sm.value_counts() #balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84979\n",
      "           1       0.24      0.88      0.38       139\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.62      0.94      0.69     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n",
      "0.9952066542916892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfs = RandomForestClassifier(n_estimators = 80,random_state=20,max_depth=7)\n",
    "rfs.fit(X_train_sm,y_train_sm)\n",
    "y_pred_rfs = rfs.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_rfs))\n",
    "print(accuracy_score(y_test,y_pred_rfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision i.e. predicting the transaction as fraud is very less here, so the model won't perform well on detecting the future fraud transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84979\n",
      "           1       0.79      0.88      0.83       139\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.89      0.94      0.91     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBClassifier()\n",
    "xgb.fit(X_train_sm,y_train_sm)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     84979\n",
      "           1       0.79      0.88      0.83       139\n",
      "\n",
      "    accuracy                           1.00     85118\n",
      "   macro avg       0.89      0.94      0.91     85118\n",
      "weighted avg       1.00      1.00      1.00     85118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Not Fraud'), Text(0, 1.5, 'Fraud')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_xgb = confusion_matrix(y_test,y_pred_xgb)\n",
    "ax = sns.heatmap(cf_xgb,annot=True,cmap=\"Blues\",fmt='g')\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Actual Values')\n",
    "ax.xaxis.set_ticklabels(['Not Fraud','Fraud'])\n",
    "ax.yaxis.set_ticklabels(['Not Fraud','Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    84963\n",
       "1      155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_pred_xgb).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "1. We performed SMOTE for reducing the impact of imbalanced dataset on our model.\n",
    "2. Random Forest doesn't performs well with minority class data (precision = 0.30 and recall= 0.88 ).\n",
    "3. XGB performs well with the fraud transactions (precision = 0.85 and recall= 0.86)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
